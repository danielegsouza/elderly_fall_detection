{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escolha do melhor algoritmo de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import os\n",
    "from sklearn.svm import SVC\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho para o diretório central\n",
    "diretorio_central = 'SisFall/SisFall_dataset'\n",
    "\n",
    "# Lista para armazenar os dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Percorre todos os arquivos no diretório central e subdiretórios\n",
    "for root, dirs, files in os.walk(diretorio_central):\n",
    "    for file in files:\n",
    "        if file.endswith('.txt'): # Verifica arquivos .txt\n",
    "            caminho_arquivo = os.path.join(root, file)\n",
    "            # Usa vírgula como delimitador de dados e ponto e vírgula como delimitador de linha\n",
    "            df = pd.read_csv(caminho_arquivo, sep=',', lineterminator=';', header=None, encoding=\"ISO-8859-1\")\n",
    "            \n",
    "            # Adiciona a coluna de rótulo com base no nome do arquivo\n",
    "            if file.startswith('D'):\n",
    "                df['queda'] = 0\n",
    "            elif file.startswith('F'):\n",
    "                df['queda'] = 1\n",
    "            \n",
    "            dataframes.append(df)\n",
    "\n",
    "# Concatena todos os dataframes em um único dataframe\n",
    "dataset = pd.concat(dataframes, ignore_index=True)\n",
    "dataset = dataset.replace('\\r\\n', '', regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0     1      2     3     4    5     6     7       8  queda\n",
      "0     9 -18.0  240.0 -12.0  74.0 -2.0  45.0 -77.0  1042.0      0\n",
      "1     9 -23.0  241.0 -14.0  73.0 -1.0  45.0 -80.0  1044.0      0\n",
      "2     9 -19.0  241.0 -13.0  73.0 -2.0  45.0 -78.0  1046.0      0\n",
      "3     8 -20.0  243.0 -15.0  71.0 -2.0  47.0 -78.0  1047.0      0\n",
      "4     8 -22.0  241.0 -14.0  69.0 -2.0  44.0 -83.0  1048.0      0\n",
      "             0     1      2     3     4    5      6      7      8  queda\n",
      "15863429   -53  77.0 -266.0 -44.0  17.0 -2.0 -231.0  305.0 -945.0      1\n",
      "15863430   -53  79.0 -269.0 -44.0  18.0 -3.0 -233.0  310.0 -944.0      1\n",
      "15863431   -53  75.0 -269.0 -44.0  20.0 -3.0 -236.0  309.0 -944.0      1\n",
      "15863432   -54  76.0 -269.0 -45.0  19.0 -3.0 -231.0  309.0 -952.0      1\n",
      "15863433         NaN    NaN   NaN   NaN  NaN    NaN    NaN    NaN      1\n",
      "(15863434, 10)\n",
      "Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 'queda'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(dataset.head()) \n",
    "print(dataset.tail())\n",
    "print(dataset.shape)\n",
    "print(dataset.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-processamento de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover as colunas 6, 7 e 8 do dataset\n",
    "dataset.drop([6, 7, 8], axis=1, inplace=True)\n",
    "\n",
    "# Renomeia as colunas de 0 a 6\n",
    "dataset.columns = ['acc_x', 'acc_y', 'acc_z', 'gir_x', 'gir_y', 'gir_z', 'queda']\n",
    "\n",
    "#Remover linhas que contem valor NaN\n",
    "dataset.dropna(inplace=True)\n",
    "\n",
    "# Salva o dataset em um arquivo csv\n",
    "dataset.to_csv('dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   acc_x  acc_y  acc_z  gir_x  gir_y  gir_z  queda\n",
      "0      9  -18.0  240.0  -12.0   74.0   -2.0      0\n",
      "1      9  -23.0  241.0  -14.0   73.0   -1.0      0\n",
      "2      9  -19.0  241.0  -13.0   73.0   -2.0      0\n",
      "3      8  -20.0  243.0  -15.0   71.0   -2.0      0\n",
      "4      8  -22.0  241.0  -14.0   69.0   -2.0      0\n",
      "5      7  -22.0  237.0  -14.0   69.0   -2.0      0\n",
      "6      6  -21.0  243.0  -13.0   68.0   -2.0      0\n",
      "7     11  -22.0  240.0  -12.0   65.0   -2.0      0\n",
      "8      7  -21.0  243.0  -10.0   62.0   -2.0      0\n",
      "9     11  -19.0  242.0   -9.0   59.0   -2.0      0\n",
      "10     7  -23.0  245.0   -6.0   58.0   -2.0      0\n",
      "11     8  -21.0  240.0   -5.0   56.0    0.0      0\n",
      "12     8  -20.0  243.0   -4.0   57.0   -1.0      0\n",
      "13    10  -23.0  236.0   -2.0   57.0    0.0      0\n",
      "14     9  -21.0  243.0   -1.0   58.0   -1.0      0\n",
      "15    14  -24.0  242.0    0.0   60.0    0.0      0\n",
      "16     8  -20.0  243.0    1.0   62.0   -1.0      0\n",
      "17     7  -18.0  242.0    2.0   63.0   -2.0      0\n",
      "18     9  -18.0  238.0    2.0   65.0   -2.0      0\n",
      "19     9  -21.0  242.0    3.0   67.0   -2.0      0\n",
      "20    13  -22.0  238.0    3.0   67.0   -1.0      0\n",
      "21    10  -21.0  246.0    2.0   69.0   -1.0      0\n",
      "22    10  -22.0  244.0    2.0   70.0   -2.0      0\n",
      "23     7  -20.0  242.0    3.0   69.0   -2.0      0\n",
      "24     6  -21.0  242.0    1.0   70.0   -3.0      0\n",
      "25     6  -18.0  241.0    0.0   70.0   -3.0      0\n",
      "26     8  -19.0  239.0    0.0   70.0   -2.0      0\n",
      "27     9  -19.0  240.0   -2.0   69.0   -3.0      0\n",
      "28     9  -20.0  241.0   -5.0   69.0   -4.0      0\n",
      "29    10  -20.0  240.0   -8.0   70.0   -2.0      0\n",
      "30    10  -21.0  241.0   -8.0   70.0   -4.0      0\n",
      "31     8  -20.0  241.0   -7.0   72.0   -3.0      0\n",
      "32     9  -18.0  243.0   -8.0   71.0   -4.0      0\n",
      "33     8  -19.0  240.0   -7.0   72.0   -2.0      0\n",
      "34     6  -21.0  243.0   -7.0   73.0   -3.0      0\n",
      "35     4  -17.0  243.0   -7.0   75.0   -4.0      0\n",
      "36     9  -20.0  241.0   -4.0   73.0   -4.0      0\n",
      "37     8  -17.0  238.0   -3.0   73.0   -4.0      0\n",
      "38     8  -20.0  241.0   -3.0   73.0   -3.0      0\n",
      "39     9  -19.0  243.0   -3.0   73.0   -2.0      0\n",
      "40     8  -20.0  239.0   -2.0   72.0   -4.0      0\n",
      "41     3  -17.0  244.0   -4.0   71.0   -4.0      0\n",
      "42     9  -19.0  242.0   -5.0   70.0   -4.0      0\n",
      "43    10  -20.0  242.0   -5.0   68.0   -4.0      0\n",
      "44     6  -17.0  243.0   -6.0   67.0   -4.0      0\n",
      "45     9  -20.0  241.0   -4.0   66.0   -5.0      0\n",
      "46    10  -19.0  242.0   -4.0   67.0   -5.0      0\n",
      "47     9  -19.0  240.0   -4.0   66.0   -5.0      0\n",
      "48    10  -22.0  243.0   -3.0   66.0   -5.0      0\n",
      "49     8  -20.0  238.0   -4.0   66.0   -5.0      0\n",
      "         acc_x  acc_y  acc_z  gir_x  gir_y  gir_z  queda\n",
      "15863428   -57   78.0 -269.0  -44.0   18.0   -2.0      1\n",
      "15863429   -53   77.0 -266.0  -44.0   17.0   -2.0      1\n",
      "15863430   -53   79.0 -269.0  -44.0   18.0   -3.0      1\n",
      "15863431   -53   75.0 -269.0  -44.0   20.0   -3.0      1\n",
      "15863432   -54   76.0 -269.0  -45.0   19.0   -3.0      1\n",
      "(15858929, 7)\n",
      "Index(['acc_x', 'acc_y', 'acc_z', 'gir_x', 'gir_y', 'gir_z', 'queda'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(dataset.head(50))\n",
    "print(dataset.tail())\n",
    "print(dataset.shape)\n",
    "print(dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ler o novo dataset\n",
    "dataset = pd.read_csv('dataset.csv')\n",
    "\n",
    "# Separa os recursos (X) e o rótulo (y)\n",
    "X = dataset.iloc[:, :-1] # Todos os dados, exceto o último (que é o rótulo)\n",
    "y = dataset.iloc[:, -1]   # Última coluna como rótulo\n",
    "\n",
    "X_scaled_df = pd.DataFrame(X, columns=X.columns)\n",
    "\n",
    "accelerometer_x = X_scaled_df.iloc[:, 0]\n",
    "accelerometer_y = X_scaled_df.iloc[:, 1]\n",
    "accelerometer_z = X_scaled_df.iloc[:, 2]\n",
    "giroscope_x = X_scaled_df.iloc[:, 3]\n",
    "giroscope_y = X_scaled_df.iloc[:, 4]\n",
    "giroscope_z = X_scaled_df.iloc[:, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extração de Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc_x', 'acc_y', 'acc_z', 'gir_x', 'gir_y', 'gir_z', 'queda']\n",
      "0   -18.0\n",
      "1   -23.0\n",
      "2   -19.0\n",
      "3   -20.0\n",
      "4   -22.0\n",
      "5   -22.0\n",
      "6   -21.0\n",
      "7   -22.0\n",
      "8   -21.0\n",
      "9   -19.0\n",
      "Name: acc_y, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Imprimir todas as colunas do DataFrame\n",
    "print(dataset.columns.tolist())\n",
    "print(accelerometer_y.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supondo que 'dataset' é seu DataFrame original\n",
    "features_dataset = pd.DataFrame()\n",
    "\n",
    "# Sum vector magnitude on horizontal plane c1=[k] = (sqrt(ax^2 [k] + az^2 [k])) (C1 feature)\n",
    "features_dataset['sum_vector_magnitude'] = np.sqrt((dataset['acc_x'] ** 2) + (dataset['acc_z'] ** 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sum vector magnitude on horizontal plane c2=[k] = (sqrt(ax^2 [k] + ay^2 [k] + az^2 [k])) (C2 feature)\n",
    "features_dataset['sum_vector_magnitude_horizontal'] = np.sqrt((dataset['acc_x'] ** 2) + (dataset['acc_y'] ** 2) + (dataset['acc_z'] ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standar deviation magnitude on horizontal plane (axial x and z) c3=[k] = std(ax [k], az [k]) (C8 feature)\n",
    "features_dataset['std_magnitude_horizontal'] = np.std([dataset['acc_x'], dataset['acc_z']], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard deviation magnitude on the three axials c3=[k] = std(ax [k], ay [k], az [k]) (C9 feature)\n",
    "features_dataset['std_magnitude'] = np.std([dataset['acc_x'], dataset['acc_y'], dataset['acc_z']], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva o dataset de features em um arquivo CSV\n",
    "features_dataset.to_csv('features_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0           240.168691\n",
      "1           241.167991\n",
      "2           241.167991\n",
      "3           243.131652\n",
      "4           241.132744\n",
      "               ...    \n",
      "15858924    274.972726\n",
      "15858925    271.228686\n",
      "15858926    274.171479\n",
      "15858927    274.171479\n",
      "15858928    274.366543\n",
      "Name: sum_vector_magnitude, Length: 15858929, dtype: float64\n",
      "(15858929, 4)\n"
     ]
    }
   ],
   "source": [
    "#imprime sum vector magnitude\n",
    "print(features_dataset['sum_vector_magnitude'])\n",
    "print(features_dataset.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   acc_x  acc_y  acc_z  gir_x  gir_y  gir_z  sum_vector_magnitude  \\\n",
      "0      9  -18.0  240.0  -12.0   74.0   -2.0            240.168691   \n",
      "1      9  -23.0  241.0  -14.0   73.0   -1.0            241.167991   \n",
      "2      9  -19.0  241.0  -13.0   73.0   -2.0            241.167991   \n",
      "3      8  -20.0  243.0  -15.0   71.0   -2.0            243.131652   \n",
      "4      8  -22.0  241.0  -14.0   69.0   -2.0            241.132744   \n",
      "\n",
      "   sum_vector_magnitude_horizontal  std_magnitude_horizontal  std_magnitude  \n",
      "0                       240.842272                     115.5     115.784282  \n",
      "1                       242.262255                     116.0     117.635973  \n",
      "2                       241.915274                     116.0     116.527536  \n",
      "3                       243.952864                     117.5     117.935010  \n",
      "4                       242.134260                     116.5     117.548099  \n"
     ]
    }
   ],
   "source": [
    "#Cria novo dataset que concatena as colunas acc_x, acc_y, acc_z, gir_x, gir_y, gir_z com sum_vector_magnitude, max_peak_to_peak, std_magnitude_horizontal e std_magnitude\n",
    "dataset_com_feature = pd.concat([X, features_dataset], axis=1)\n",
    "print(dataset_com_feature.head())\n",
    "\n",
    "#Salva o dataset com as features em um arquivo csv\n",
    "dataset_com_feature.to_csv('dataset_com_feature.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new-tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
